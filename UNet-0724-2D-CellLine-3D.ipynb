{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os,sys\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class, in_channels,dropout=0.2):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(in_channels, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "        self.dconv_down5 = double_conv(512, 1024)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up4 = double_conv(512 + 1024, 512)\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, in_channels, 1)\n",
    "        self.fc1 = nn.Linear(25600 ,1024)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(1024, n_class)\n",
    "        self.relu = nn.ReLU()\n",
    "#         self.init_weights()\n",
    "        \n",
    "#     def init_weights(self):\n",
    "#         self.dconv_down1.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_down2.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_down3.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_down4.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_up3.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_up2.weight.data.normal_(0, 0.01)\n",
    "#         self.dconv_up1.weight.data.normal_(0, 0.01)\n",
    "#         self.conv_last.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        conv4 = self.dconv_down4(x)\n",
    "        x = self.maxpool(conv4) \n",
    "    \n",
    "        x = self.dconv_down5(x) \n",
    "        \n",
    "        #Classifier\n",
    "        flatten = x.view(x.size(0),-1)\n",
    "#         print('fc:',flatten.size())\n",
    "        y = self.fc1(flatten)\n",
    "        y = self.bn_fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout1(y)\n",
    "\n",
    "        y = self.out(y)\n",
    "#         print('out:',x.size())\n",
    "        prediction = nn.functional.log_softmax(y,dim=1)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "        x = self.dconv_up4(x)\n",
    "        \n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        out = self.relu(out)\n",
    "        return out,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "# print(m)\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        m.weight.data.normal_(0, 0.0001)\n",
    "# print(m.weight)\n",
    "\n",
    "# net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "# net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = UNet(3,1)\n",
    "# model.apply(init_weights)\n",
    "# model = model.to(device)\n",
    "# # model\n",
    "# summary(model, input_size=(1, 80, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(out, prediction, target, original, metrics, MSE_weight=0.5):\n",
    "    CE = F.cross_entropy(prediction, target)\n",
    "#     BCE = F.binary_cross_entropy_with_logits(prediction, target)\n",
    "#     out = torch.sigmoid(out)\n",
    "    MSE = F.mse_loss(out*65535, original*65535)\n",
    "    \n",
    "    loss = MSE * MSE_weight + CE * (1 - MSE_weight)\n",
    "#     loss = MSE * MSE_weight + CE\n",
    "    \n",
    "    metrics['CE'] += CE.data.cpu().numpy() * target.size(0)\n",
    "    metrics['MSE'] += MSE.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer1, optimizer2, scheduler1, scheduler2, num_epochs=25):\n",
    "    start = datetime.now()\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    val_Bacc_history = []\n",
    "    train_Bacc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    val_MSEloss_history = []\n",
    "    lr_history = []\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            LabelList = torch.tensor([1]).to(device)\n",
    "            PredList = torch.tensor([1]).to(device)\n",
    "            if phase == 'train':\n",
    "                if epoch < 5:\n",
    "                    for param_group in optimizer1.param_groups:\n",
    "                        print(\"LR\", param_group['lr'])\n",
    "                        lr_history.append(param_group['lr'])\n",
    "                else:\n",
    "                    for param_group in optimizer2.param_groups:\n",
    "                        print(\"LR\", param_group['lr'])\n",
    "                        lr_history.append(param_group['lr'])\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "#             running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            confusion_matrix = torch.zeros(3, 3)\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                if epoch < 5:\n",
    "                    optimizer1.zero_grad()\n",
    "                else:\n",
    "                    optimizer2.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs,predictions = model(inputs)\n",
    "                    loss = calc_loss(outputs, predictions,labels,inputs, metrics,MSE_weight = 1e-8)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        if epoch < 5:\n",
    "                            optimizer1.step()\n",
    "                        else:\n",
    "                            optimizer2.step()\n",
    "                _, preds = torch.max(predictions, 1)\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "                LabelList = torch.cat([LabelList,labels.view(-1)],dim=0)\n",
    "                PredList = torch.cat([PredList, preds.view(-1)],dim=0)\n",
    "#                 # statistics\n",
    "#                 for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "#                     confusion_matrix[t.long(), p.long()] += 1\n",
    "                  \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            \n",
    "#             confusionMat = np.asarray(confusion_matrix)\n",
    "#             sumconfusion = np.sum(confusionMat,axis = 1).T\n",
    "\n",
    "#             summat = np.tile(sumconfusion,(3,1)).T\n",
    "            # print(test)\n",
    "#             percentconfusion = np.divide(confusionMat,summat)\n",
    "            epoch_acc_balanced = balanced_accuracy_score(LabelList[1:].cpu(), PredList[1:].cpu())\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "            epoch_acc = running_corrects.double() / epoch_samples\n",
    "            print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "            print('{} Bal. Acc: {:.4f}'.format(phase, epoch_acc_balanced))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(\"saving best model\")\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_Bacc_history.append(epoch_acc_balanced)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_MSEloss_history.append(metrics['MSE']/epoch_samples)\n",
    "                if epoch < 5:\n",
    "                    scheduler1.step(epoch_loss)\n",
    "                elif epoch > num_epochs * (2/3):\n",
    "                    scheduler2.step(epoch_loss)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_Bacc_history.append(epoch_acc_balanced)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "#             if epoch_acc == 1:\n",
    "#                 break\n",
    "        \n",
    "        if epoch > 10 and val_MSEloss_history[-1] > 3.5e7 :\n",
    "                break\n",
    "        print(\"Total time: %s\" %(datetime.now() - start))\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_acc_history,train_loss_history,val_acc_history,val_loss_history,lr_history,train_Bacc_history,val_Bacc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadir = \"H:\\\\CellLineClassification\\\\3DImages\\\\3DImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def datapreparation(Datadir):\n",
    "    trainpath = []\n",
    "    trainlabel = []\n",
    "    fpath = []\n",
    "    traindir = Datadir + \"\\\\HEK\"\n",
    "    for dirpath, dirnames, filenames in os.walk(traindir):\n",
    "        for filename in [f for f in filenames if f.endswith(\".tif\")]:\n",
    "            tempfpath =os.path.join(dirpath, filename)\n",
    "            fpath.append(tempfpath)\n",
    "    train = list(range(1,len(fpath)))\n",
    "    print('HEK data: %d' %(len(train)))\n",
    "    for i in train:\n",
    "        trainpath.append(fpath[i])\n",
    "        trainlabel.append(0)\n",
    "\n",
    "    fpath = []\n",
    "    traindir = Datadir + \"\\\\HELA\"\n",
    "    for dirpath, dirnames, filenames in os.walk(traindir):\n",
    "        for filename in [f for f in filenames if f.endswith(\".tif\")]:\n",
    "            tempfpath =os.path.join(dirpath, filename)\n",
    "            fpath.append(tempfpath)\n",
    "    train = list(range(1,len(fpath)))\n",
    "    print('HELA data: %d' %(len(train)))\n",
    "    for i in train:\n",
    "        trainpath.append(fpath[i]) \n",
    "        trainlabel.append(1)\n",
    "\n",
    "    fpath = []\n",
    "    traindir = Datadir + \"\\\\MCF7\"\n",
    "    for dirpath, dirnames, filenames in os.walk(traindir):\n",
    "        for filename in [f for f in filenames if f.endswith(\".tif\")]:\n",
    "            tempfpath =os.path.join(dirpath, filename)\n",
    "            fpath.append(tempfpath)\n",
    "    train = list(range(1,len(fpath)))\n",
    "    print('MCF7 data: %d' %(len(train)))\n",
    "    for i in train:\n",
    "        trainpath.append(fpath[i])\n",
    "        trainlabel.append(2)\n",
    "    return trainpath,trainlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEK data: 3191\n",
      "HELA data: 3315\n",
      "MCF7 data: 3764\n"
     ]
    }
   ],
   "source": [
    "X, Y = datapreparation(Datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [  639   640   641 ... 10267 10268 10269] \n",
      "\n",
      "Test Index:  [   0    1    2 ... 7255 7256 7257]\n",
      "Train Index:  [    0     1     2 ... 10267 10268 10269] \n",
      "\n",
      "Test Index:  [ 639  640  641 ... 8008 8009 8010]\n",
      "Train Index:  [    0     1     2 ... 10267 10268 10269] \n",
      "\n",
      "Test Index:  [1277 1278 1279 ... 8761 8762 8763]\n",
      "Train Index:  [    0     1     2 ... 10267 10268 10269] \n",
      "\n",
      "Test Index:  [1915 1916 1917 ... 9514 9515 9516]\n",
      "Train Index:  [   0    1    2 ... 9514 9515 9516] \n",
      "\n",
      "Test Index:  [ 2553  2554  2555 ... 10267 10268 10269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11821\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n",
    "trainindex = {}\n",
    "testindex = {}\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X,Y):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n",
    "    trainindex[i] = train_index\n",
    "    testindex[i] = test_index\n",
    "    i = i + 1\n",
    "#fold - 0\n",
    "# print(trainindex[1])\n",
    "# indices = trainindex[1]\n",
    "trainpath =[X[i] for i in trainindex[1]]\n",
    "testpath =[X[i] for i in testindex[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import skimage.transform\n",
    "import scipy\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mat_paths, transforms=None):\n",
    "        self.paths = mat_paths\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Load .mat\n",
    "#         data = loadmat(self.paths[index])\n",
    "        data = io.imread(self.paths[index])\n",
    "#         reshape = skimage.transform.resize(data,(224,224,40))\n",
    "#         x = torch.from_numpy(reshape.astype(np.float32))\n",
    "        x = torch.from_numpy(data.astype(np.float32)/65535)\n",
    "#         x = x.unsqueeze(dim = 0)\n",
    "        x = np.transpose(x,(2,0,1))\n",
    "#         x = np.transpose(np.array(data['Data']),(2,0,1))\n",
    "        if 'HEK' in self.paths[index]:\n",
    "            label = int(0)\n",
    "        elif 'HELA' in self.paths[index]:\n",
    "            label = int(1)\n",
    "        elif 'MCF7' in self.paths[index]:\n",
    "            label = int(2)\n",
    "        if self.transforms:\n",
    "            x= self.transforms(x)\n",
    "        return x,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data volume:  8216\n",
      "validation data volume:  2054\n",
      "Cell Label:  HEK-293\n",
      "image tensor shape:  torch.Size([80, 80, 80])\n",
      "image tensor dtype:  torch.float32\n",
      "image shape:  (80, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "#actual training\n",
    "image_datasets = {}\n",
    "mini_datasets ={}\n",
    "image_datasets['train'] = MyDataset(trainpath)\n",
    "image_datasets['val'] = MyDataset(testpath)\n",
    "# mini_datasets['train'] = MyDataset(minitrainpath)\n",
    "# mini_datasets['val'] = MyDataset(minivalpath)\n",
    "# model testing\n",
    "# image_datasets['train'] = MyDataset(valpath)\n",
    "# image_datasets['val'] = MyDataset(testpath)\n",
    "# test_datasets['val'] = MyDataset(testpath)\n",
    "print('training data volume: ', image_datasets['train'].__len__())\n",
    "print('validation data volume: ', image_datasets['val'].__len__())\n",
    "\n",
    "# print('mini-training data volume: ', mini_datasets['train'].__len__())\n",
    "# print('mini-validation data volume: ', mini_datasets['val'].__len__())\n",
    "\n",
    "CellName = ['HEK-293','HeLa','MCF-7']\n",
    "image_datasets['train'].__getitem__(0)[0].shape\n",
    "[ImgTensor,ImgLabel] = image_datasets['train'].__getitem__(0)\n",
    "print('Cell Label: ',CellName[ImgLabel])\n",
    "print('image tensor shape: ', ImgTensor.shape)\n",
    "print('image tensor dtype: ', ImgTensor.dtype)\n",
    "image_datasets['train'].__getitem__(0)[0]\n",
    "\n",
    "#Visualize image stacks\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "image = np.squeeze(ImgTensor.numpy())\n",
    "print('image shape: ', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11821\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize image stacks\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "image = np.transpose(ImgTensor.numpy(), (1,2,0))\n",
    "\n",
    "def DisplayImage(img,MinLim,MaxLim): \n",
    "    plt.figure(figsize=(20,20))\n",
    "    for depth in range (0,80,8):\n",
    "        \n",
    "        plt.subplot(1,10,depth/8+1)\n",
    "        fig4 = plt.imshow(img[:,:,depth],vmin=MinLim, vmax=MaxLim, cmap ='jet')\n",
    "        fig4.axes.get_xaxis().set_visible(False)\n",
    "        fig4.axes.get_yaxis().set_visible(False)\n",
    "        # plt.colorbar()\n",
    "        plt.title('z = '+ str(depth))\n",
    "        if depth==72:\n",
    "            plt.subplot(1,10,depth/8+1)\n",
    "            plt.title('z = '+ str(depth))\n",
    "            ax = plt.gca()\n",
    "            fig4 = plt.imshow(img[:,:,depth],vmin=MinLim, vmax=MaxLim, cmap ='jet')\n",
    "            fig4.axes.get_xaxis().set_visible(False)\n",
    "            fig4.axes.get_yaxis().set_visible(False)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(fig4, cax=cax)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "DisplayImage(image,image.min(),image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "# Create training and validation datasets\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold- 1 : Initializing Datasets and Dataloaders...\n",
      "Epoch 0/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.971297, MSE: 55013483.295034, loss: 1.521432\n",
      "train Acc: 0.4676\n",
      "train Bal. Acc: 0.4897\n",
      "val: CE: 0.945725, MSE: 50116284.393379, loss: 1.446888\n",
      "val Acc: 0.5190\n",
      "val Bal. Acc: 0.5409\n",
      "saving best model\n",
      "Total time: 0:03:05.561391\n",
      "Epoch time: 3m 6s\n",
      "Epoch 1/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.850033, MSE: 46622503.707887, loss: 1.316258\n",
      "train Acc: 0.5955\n",
      "train Bal. Acc: 0.6042\n",
      "val: CE: 0.796834, MSE: 46427098.227848, loss: 1.261105\n",
      "val Acc: 0.6154\n",
      "val Bal. Acc: 0.6269\n",
      "saving best model\n",
      "Total time: 0:06:12.379452\n",
      "Epoch time: 3m 7s\n",
      "Epoch 2/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.721743, MSE: 43296912.708861, loss: 1.154712\n",
      "train Acc: 0.6884\n",
      "train Bal. Acc: 0.6909\n",
      "val: CE: 0.607157, MSE: 43497261.670886, loss: 1.042130\n",
      "val Acc: 0.7128\n",
      "val Bal. Acc: 0.7075\n",
      "saving best model\n",
      "Total time: 0:09:18.897877\n",
      "Epoch time: 3m 7s\n",
      "Epoch 3/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.636566, MSE: 41646303.517040, loss: 1.053029\n",
      "train Acc: 0.7360\n",
      "train Bal. Acc: 0.7381\n",
      "val: CE: 0.585840, MSE: 43102300.958130, loss: 1.016863\n",
      "val Acc: 0.7527\n",
      "val Bal. Acc: 0.7630\n",
      "saving best model\n",
      "Total time: 0:12:24.818141\n",
      "Epoch time: 3m 6s\n",
      "Epoch 4/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.558438, MSE: 41453740.852970, loss: 0.972976\n",
      "train Acc: 0.7770\n",
      "train Bal. Acc: 0.7790\n",
      "val: CE: 0.548456, MSE: 43007546.488802, loss: 0.978532\n",
      "val Acc: 0.7644\n",
      "val Bal. Acc: 0.7667\n",
      "saving best model\n",
      "Total time: 0:15:30.540139\n",
      "Epoch time: 3m 6s\n",
      "Epoch 5/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.489867, MSE: 41450671.439143, loss: 0.904374\n",
      "train Acc: 0.8036\n",
      "train Bal. Acc: 0.8048\n",
      "val: CE: 0.503804, MSE: 42957363.279455, loss: 0.933378\n",
      "val Acc: 0.7799\n",
      "val Bal. Acc: 0.7750\n",
      "saving best model\n",
      "Total time: 0:18:37.198300\n",
      "Epoch time: 3m 7s\n",
      "Epoch 6/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.444586, MSE: 41270725.133398, loss: 0.857294\n",
      "train Acc: 0.8253\n",
      "train Bal. Acc: 0.8261\n",
      "val: CE: 0.551647, MSE: 42787291.645570, loss: 0.979520\n",
      "val Acc: 0.7580\n",
      "val Bal. Acc: 0.7568\n",
      "Total time: 0:21:43.080714\n",
      "Epoch time: 3m 6s\n",
      "Epoch 7/99\n",
      "----------\n",
      "LR 0.0001\n",
      "train: CE: 0.396798, MSE: 41184556.284323, loss: 0.808644\n",
      "train Acc: 0.8490\n",
      "train Bal. Acc: 0.8495\n",
      "val: CE: 0.407628, MSE: 42835623.672833, loss: 0.835984\n",
      "val Acc: 0.8228\n",
      "val Bal. Acc: 0.8175\n",
      "saving best model\n",
      "Total time: 0:24:50.480330\n",
      "Epoch time: 3m 7s\n",
      "Epoch 8/99\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-de01f042a501>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mexp_lr_scheduler1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_ft1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcooldown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-08\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mexp_lr_scheduler2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_ft2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcooldown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-08\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscratch_hist_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_hist_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscratch_hist_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_hist_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_hist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Bacc_hist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_Bacc_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer_ft1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_lr_scheduler1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp_lr_scheduler2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_hist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model diverges, reinitializing training....\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d6a24c20d13e>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, optimizer1, optimizer2, scheduler1, scheduler2, num_epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mrunning_corrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ebcf8992acae>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Load .mat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         data = loadmat(self.paths[index])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         reshape = skimage.transform.resize(data,(224,224,40))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         x = torch.from_numpy(reshape.astype(np.float32))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m                                (plugin, kind))\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\io\\_plugins\\tifffile_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, dtype, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# read and return tiff as numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mTiffFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs_tiff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(self, key, series, memmap, tempdir)\u001b[0m\n\u001b[0;32m   1565\u001b[0m                     series.dtype, product(series.shape))\n\u001b[0;32m   1566\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36mstack_pages\u001b[1;34m(pages, memmap, tempdir, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4869\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mdata0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4870\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4871\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4873\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch-gpu\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(self, squeeze, colormapped, rgbonly, scale_mdgel, memmap, reopen, maxsize)\u001b[0m\n\u001b[0;32m   2616\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlsb2msb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2617\u001b[0m                         \u001b[0mstrip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_bitorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2618\u001b[1;33m                     \u001b[0mstrip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2619\u001b[0m                     \u001b[0mstrip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m                     size = min(result.size, strip.size, strip_size,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "for runs in range (1,5):\n",
    "    print(\"Fold-\",str(runs),\": Initializing Datasets and Dataloaders...\")\n",
    "    #Kfold\n",
    "    trainpath =[X[i] for i in trainindex[runs]]\n",
    "    testpath =[X[i] for i in testindex[runs]]\n",
    "    image_datasets = {}\n",
    "    image_datasets['train'] = MyDataset(trainpath)\n",
    "    image_datasets['val'] = MyDataset(testpath)\n",
    "\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'val']}\n",
    "\n",
    "    # Detect if we have a GPU available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_class = 3\n",
    "    in_channel = 80\n",
    "    num_epochs = 100\n",
    "    loss_hist_train = []\n",
    "    while (len(loss_hist_train)<num_epochs/2):\n",
    "        model = UNet(num_class, in_channel)\n",
    "        model.apply(init_weights)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # freeze backbone layers\n",
    "        # Comment out to finetune further\n",
    "        # for l in model.base_layers:\n",
    "        #     for param in l.parameters():\n",
    "        #         param.requires_grad = False\n",
    "\n",
    "        optimizer_ft1 = optim.Adam(model.parameters(), lr=1e-4,betas = (0.9, 0.999),eps=1e-08,weight_decay=0)\n",
    "        optimizer_ft2 = optim.Adam(model.parameters(), lr=1e-4,betas = (0.9, 0.999),eps=1e-08,weight_decay=0)\n",
    "        # optimizer_ft1 = optim.Adadelta(model.parameters(), lr=1e-3, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "        # optimizer_ft2 = optim.Adadelta(model.parameters(), lr=1e-3, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "        # exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1) \n",
    "        exp_lr_scheduler1 = lr_scheduler.ReduceLROnPlateau(optimizer_ft1, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=1, min_lr=1e-7, eps=1e-08)\n",
    "        exp_lr_scheduler2 = lr_scheduler.ReduceLROnPlateau(optimizer_ft2, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=1, min_lr=1e-7, eps=1e-08)       \n",
    "        model, scratch_hist_train,loss_hist_train,scratch_hist_val, loss_hist_val,lr_hist,train_Bacc_hist,val_Bacc_hist = train_model(model, dataloaders_dict,optimizer_ft1, optimizer_ft2, exp_lr_scheduler1,exp_lr_scheduler2, num_epochs)\n",
    "        if len(lr_hist)<num_epochs:\n",
    "            print('model diverges, reinitializing training....\\n')\n",
    "            print(\"Fold-\",str(runs),\": Initializing Datasets and Dataloaders...\")\n",
    "        \n",
    "    # num_epochs=15\n",
    "    fname1 = \"training_acc_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname1,scratch_hist_train , delimiter=\",\")\n",
    "    fname2 = \"validation_acc_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname2,scratch_hist_val , delimiter=\",\")\n",
    "    fname13 = \"training_Bacc_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname13,train_Bacc_hist, delimiter=\",\")\n",
    "    fname23 = \"validation_Bacc_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname23,val_Bacc_hist, delimiter=\",\")\n",
    "    fname20 = \"training_loss_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname20,loss_hist_train , delimiter=\",\")\n",
    "    fname21 = \"validation_loss_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname21,loss_hist_val , delimiter=\",\")\n",
    "    fname22 = \"learning_rate_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname22,lr_hist , delimiter=\",\")\n",
    "\n",
    "    shist = []\n",
    "    shist1 = []\n",
    "\n",
    "    shist = [h.cpu().numpy() for h in scratch_hist_val]\n",
    "    shist1 = [h.cpu().numpy() for h in scratch_hist_train]\n",
    "    print(len(shist))\n",
    "    plt.title(\"Training Accuracy vs. Number of Training Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Accuracy of Scratch Model\")\n",
    "    plt.plot(range(1,len(shist)+1),shist[0:len(shist)],label=\"Validation\")\n",
    "    plt.plot(range(1,len(shist)+1),shist1[0:len(shist)],label=\"Training\")\n",
    "    plt.ylim((0.5,1.))\n",
    "    plt.xticks(np.arange(0, num_epochs, 10.0))\n",
    "    plt.legend()\n",
    "    fname3 = 'training_curve_'+str(runs)+'.png'\n",
    "    plt.savefig(fname3)\n",
    "    plt.show()\n",
    "\n",
    "    shist = [h.cpu().numpy() for h in scratch_hist_val]\n",
    "    shist1 = [h.cpu().numpy() for h in scratch_hist_train]\n",
    "    print(len(shist))\n",
    "    plt.title(\"Classification Accuracy vs. Number of Training Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Accuracy of CNN Model\")\n",
    "    plt.plot(range(1,len(shist)+1),shist[0:len(shist)],label=\"Validation\")\n",
    "    plt.plot(range(1,len(shist)+1),shist1[0:len(shist)],label=\"Training\")\n",
    "    plt.ylim((0.3,1.1))\n",
    "    plt.xticks(np.arange(0, len(shist)+10, 5.0))\n",
    "    plt.legend()\n",
    "    fname3 = 'training_curve_'+str(runs)+'backup'+'.png'\n",
    "    plt.savefig(fname3)\n",
    "    plt.show()\n",
    "\n",
    "    train_loss = [h for h in loss_hist_train]\n",
    "    val_loss = [h for h in loss_hist_val]\n",
    "    plt.title(\"Cross-entropy Loss vs. Number of Training Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Cross-entropy Loss of CNN Model\")\n",
    "    plt.plot(range(1,len(val_loss)+1),val_loss[0:len(val_loss)],label=\"Validation\")\n",
    "    plt.plot(range(1,len(train_loss)+1),train_loss[0:len(train_loss)],label=\"Training\")\n",
    "    #     plt.ylim((0.5,1.05))\n",
    "    plt.xticks(np.arange(0, len(val_loss)+5, 5.0))\n",
    "    plt.legend()\n",
    "    fname31 = 'loss_curve_'+str(runs)+'.png'\n",
    "    plt.savefig(fname31)\n",
    "    plt.show()\n",
    "\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(dataloaders_dict['val']):\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            _, outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    print(confusion_matrix)\n",
    "    confusionMat = np.asarray(confusion_matrix)\n",
    "    sumconfusion = np.sum(confusionMat,axis = 1).T\n",
    "    summat = np.tile(sumconfusion,(3,1)).T\n",
    "    percentconfusion = np.divide(confusionMat,summat)\n",
    "    print(percentconfusion)\n",
    "    fname4 = \"confusion_Mat_UNet_confusionMat_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname4,confusionMat , delimiter=\",\")\n",
    "    fname5 = \"confusion_Mat_UNet_confusionPer_\"+str(runs)+\".csv\"\n",
    "    np.savetxt(fname5,percentconfusion , delimiter=\",\")\n",
    "    fname6 = 'celltypemodel-UNet2D3D_Run_'+str(runs)+'.pth.tar'\n",
    "\n",
    "    torch.save(model,fname6)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 0\n",
    "# num_epochs=15\n",
    "fname1 = \"training_acc_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname1,scratch_hist_train , delimiter=\",\")\n",
    "fname2 = \"validation_acc_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname2,scratch_hist_val , delimiter=\",\")\n",
    "fname13 = \"training_Bacc_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname13,train_Bacc_hist, delimiter=\",\")\n",
    "fname23 = \"validation_Bacc_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname23,val_Bacc_hist, delimiter=\",\")\n",
    "fname20 = \"training_loss_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname20,loss_hist_train , delimiter=\",\")\n",
    "fname21 = \"validation_loss_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname21,loss_hist_val , delimiter=\",\")\n",
    "fname22 = \"learning_rate_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname22,lr_hist , delimiter=\",\")\n",
    "\n",
    "shist = []\n",
    "shist1 = []\n",
    "\n",
    "shist = [h.cpu().numpy() for h in scratch_hist_val]\n",
    "shist1 = [h.cpu().numpy() for h in scratch_hist_train]\n",
    "print(len(shist))\n",
    "plt.title(\"Training Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy of Scratch Model\")\n",
    "plt.plot(range(1,len(shist)+1),shist[0:len(shist)],label=\"Validation\")\n",
    "plt.plot(range(1,len(shist)+1),shist1[0:len(shist)],label=\"Training\")\n",
    "plt.ylim((0.5,1.))\n",
    "plt.xticks(np.arange(0, num_epochs, 10.0))\n",
    "plt.legend()\n",
    "fname3 = 'training_curve_'+str(runs)+'.png'\n",
    "plt.savefig(fname3)\n",
    "plt.show()\n",
    "\n",
    "shist = [h.cpu().numpy() for h in scratch_hist_val]\n",
    "shist1 = [h.cpu().numpy() for h in scratch_hist_train]\n",
    "print(len(shist))\n",
    "plt.title(\"Classification Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy of CNN Model\")\n",
    "plt.plot(range(1,len(shist)+1),shist[0:len(shist)],label=\"Validation\")\n",
    "plt.plot(range(1,len(shist)+1),shist1[0:len(shist)],label=\"Training\")\n",
    "plt.ylim((0.3,1.1))\n",
    "plt.xticks(np.arange(0, len(shist)+10, 5.0))\n",
    "plt.legend()\n",
    "fname3 = 'training_curve_'+str(runs)+'backup'+'.png'\n",
    "plt.savefig(fname3)\n",
    "plt.show()\n",
    "\n",
    "train_loss = [h for h in loss_hist_train]\n",
    "val_loss = [h for h in loss_hist_val]\n",
    "plt.title(\"Cross-entropy Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Cross-entropy Loss of CNN Model\")\n",
    "plt.plot(range(1,len(val_loss)+1),val_loss[0:len(val_loss)],label=\"Validation\")\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss[0:len(train_loss)],label=\"Training\")\n",
    "#     plt.ylim((0.5,1.05))\n",
    "plt.xticks(np.arange(0, len(val_loss)+5, 5.0))\n",
    "plt.legend()\n",
    "fname31 = 'loss_curve_'+str(runs)+'.png'\n",
    "plt.savefig(fname31)\n",
    "plt.show()\n",
    "\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders_dict['val']):\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        _, outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)\n",
    "confusionMat = np.asarray(confusion_matrix)\n",
    "sumconfusion = np.sum(confusionMat,axis = 1).T\n",
    "summat = np.tile(sumconfusion,(3,1)).T\n",
    "percentconfusion = np.divide(confusionMat,summat)\n",
    "print(percentconfusion)\n",
    "fname4 = \"confusion_Mat_UNet_confusionMat_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname4,confusionMat , delimiter=\",\")\n",
    "fname5 = \"confusion_Mat_UNet_confusionPer_\"+str(runs)+\".csv\"\n",
    "np.savetxt(fname5,percentconfusion , delimiter=\",\")\n",
    "fname6 = 'celltypemodel-UNet2D3D_Run_'+str(runs)+'.pth.tar'\n",
    "\n",
    "torch.save(model,fname6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.1%}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.tile(np.sum(cf,axis = 0),(3,))]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "#         accuracy  = np.trace(cf) / 3\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nBalanced Accuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(percentconfusion, annot=True,cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = CellName\n",
    "make_confusion_matrix(percentconfusion, \n",
    "                      #group_names=labels,\n",
    "                      categories=categories,\n",
    "                      percent=False,\n",
    "                      cbar=False,\n",
    "                      figsize=(4 ,4),\n",
    "                      cmap='Oranges',title = '2DCNN UNet - 2D Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxpool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model = torch.load('celltypemodel-unet_80rech_Run_1.pth.tar')\n",
    "scratch_model_fc = nn.Sequential(*(list(scratch_model.children())[:1]),maxpool(),*(list(scratch_model.children())[1:2]),maxpool(),*(list(scratch_model.children())[2:3]),maxpool(),*(list(scratch_model.children())[3:4]),maxpool(),Flatten(),*(list(scratch_model.children())[-5:-3]))\n",
    "# scratch_model_fc = nn.Sequential(*list(scratch_model.children())[:-3])\n",
    "scratch_model_fc = scratch_model_fc.to(device)\n",
    "scratch_model_fc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(scratch_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "image_datasets = {}\n",
    "test_datasets ={}\n",
    "image_datasets['train'] = MyDataset(trainpath)\n",
    "image_datasets['val'] = MyDataset(testpath)\n",
    "image_datasets['val'].__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 128\n",
    "# Create training and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=0) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders_dict['val']):\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = scratch_model_fc(inputs)\n",
    "        outputs = outputs.cpu().clone().numpy()\n",
    "        if i == 0:\n",
    "            outputlist = outputs\n",
    "            y = classes.cpu().clone().numpy()\n",
    "        else:\n",
    "            outputlist = np.append(outputlist,outputs, axis=0)\n",
    "            y = np.append(y,classes.cpu().clone().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(outputlist))\n",
    "print(outputlist.shape)\n",
    "print(y.shape)\n",
    "outputlist = np.squeeze(outputlist)\n",
    "print(outputlist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne = TSNE(n_components=2, random_state=0,verbose=1, perplexity=45, learning_rate=200,early_exaggeration = 50, n_iter=2000)\n",
    "X_2d = tsne.fit_transform(outputlist)\n",
    "CellName = ['HEK293','HELA','MCF7']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = range(len(outputlist))\n",
    "plt.figure(figsize=(4,4))\n",
    "colors = 'r', 'g', 'b'\n",
    "for i, c, label in zip(target_ids, colors, CellName):\n",
    "    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1],s=3, c=c, label=label,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('2DCNN UNet - 2D Input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model = torch.load('celltypemodel-unet_80rech_Run_1.pth.tar')\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CellName = ['HEK293','HELA','MCF7']\n",
    "ImgTensor, Label = image_datasets['val'].__getitem__(1)\n",
    "image = np.transpose(ImgTensor.numpy(), (1,2,0))\n",
    "print('Ground Truth Cell Type: ', CellName[Label])\n",
    "DisplayImage(image,image.min(),image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.unsqueeze(ImgTensor,0).to(device)\n",
    "[output,prediction] = scratch_model(inputs)\n",
    "# output = output.squeeze()\n",
    "output = output.squeeze()\n",
    "output = output.cpu().clone().detach().numpy()\n",
    "_, preds = torch.max(prediction, 1)\n",
    "preds = preds.cpu().clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output/output.max())\n",
    "print(output.max())\n",
    "print(output.shape)\n",
    "print('Predicted Cell Type: ', CellName[preds])\n",
    "image = np.transpose(output, (1,2,0))\n",
    "DisplayImage(image,image.min(),image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
